{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"happyness.ipynb","version":"0.3.2","views":{},"default_view":{},"provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 2","language":"python","name":"python2"}},"cells":[{"metadata":{"id":"mvQPp5xtgk95","colab_type":"text"},"cell_type":"markdown","source":["### Introduction\n","\n","Here you'll learn to build models using Catboost, Lightgbm and NaiveBayes algorithm in Python. Given the text classification problem, you'll also learn to clean data, create bag of words matrix, tf-idf matrix. \n","\n","On top of what's done here, next you can create a simple voting ensemble from the predictions generated from these models here."]},{"metadata":{"id":"mpVK6CLZgk97","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# Load Libraries\n","import numpy as np\n","import pandas as pd\n","from sklearn.ensemble import GradientBoostingClassifier\n","from sklearn.naive_bayes import GaussianNB\n","from sklearn.preprocessing import LabelEncoder\n","import re\n","from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n","from sklearn.model_selection import cross_val_score\n","from sklearn.metrics import accuracy_score, make_scorer"],"execution_count":0,"outputs":[]},{"metadata":{"id":"hiAxwNwbgk9_","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# load data\n","train = pd.read_csv(\"train.csv\")\n","test = pd.read_csv(\"test.csv\")"],"execution_count":0,"outputs":[]},{"metadata":{"id":"AtlTE7hCgk-B","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"output_extras":[{}]},"outputId":"d1200191-cf2e-414c-d9ca-ae713cd02b1e"},"cell_type":"code","source":["train.head(8)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style>\n","    .dataframe thead tr:only-child th {\n","        text-align: right;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: left;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>User_ID</th>\n","      <th>Description</th>\n","      <th>Browser_Used</th>\n","      <th>Device_Used</th>\n","      <th>Is_Response</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>id10326</td>\n","      <td>The room was kind of clean but had a VERY stro...</td>\n","      <td>Edge</td>\n","      <td>Mobile</td>\n","      <td>not happy</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>id10327</td>\n","      <td>I stayed at the Crown Plaza April -- - April -...</td>\n","      <td>Internet Explorer</td>\n","      <td>Mobile</td>\n","      <td>not happy</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>id10328</td>\n","      <td>I booked this hotel through Hotwire at the low...</td>\n","      <td>Mozilla</td>\n","      <td>Tablet</td>\n","      <td>not happy</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>id10329</td>\n","      <td>Stayed here with husband and sons on the way t...</td>\n","      <td>InternetExplorer</td>\n","      <td>Desktop</td>\n","      <td>happy</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>id10330</td>\n","      <td>My girlfriends and I stayed here to celebrate ...</td>\n","      <td>Edge</td>\n","      <td>Tablet</td>\n","      <td>not happy</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>id10331</td>\n","      <td>We had - rooms. One was very nice and clearly ...</td>\n","      <td>InternetExplorer</td>\n","      <td>Desktop</td>\n","      <td>happy</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>id10332</td>\n","      <td>My husband and I have stayed in this hotel a f...</td>\n","      <td>Firefox</td>\n","      <td>Tablet</td>\n","      <td>not happy</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>id10333</td>\n","      <td>My wife &amp; I stayed in this glorious city a whi...</td>\n","      <td>Google Chrome</td>\n","      <td>Mobile</td>\n","      <td>happy</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   User_ID                                        Description  \\\n","0  id10326  The room was kind of clean but had a VERY stro...   \n","1  id10327  I stayed at the Crown Plaza April -- - April -...   \n","2  id10328  I booked this hotel through Hotwire at the low...   \n","3  id10329  Stayed here with husband and sons on the way t...   \n","4  id10330  My girlfriends and I stayed here to celebrate ...   \n","5  id10331  We had - rooms. One was very nice and clearly ...   \n","6  id10332  My husband and I have stayed in this hotel a f...   \n","7  id10333  My wife & I stayed in this glorious city a whi...   \n","\n","        Browser_Used Device_Used Is_Response  \n","0               Edge      Mobile   not happy  \n","1  Internet Explorer      Mobile   not happy  \n","2            Mozilla      Tablet   not happy  \n","3   InternetExplorer     Desktop       happy  \n","4               Edge      Tablet   not happy  \n","5   InternetExplorer     Desktop       happy  \n","6            Firefox      Tablet   not happy  \n","7      Google Chrome      Mobile       happy  "]},"metadata":{"tags":[]},"execution_count":3}]},{"metadata":{"id":"FHWiNM5igk-H","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# function to clean data\n","# import nltk\n","\n","# nltk.download()\n","# stops = set(stopwords.words(\"english\"))\n","\n","stops = []\n","\n","def cleanData(text, lowercase = False, remove_stops = False, stemming = False):\n","    txt = str(text)\n","    txt = re.sub(r'[^A-Za-z0-9\\s]',r'',txt)\n","    txt = re.sub(r'\\n',r' ',txt)\n","    \n","    if lowercase:\n","        txt = \" \".join([w.lower() for w in txt.split()])\n","        \n","    if remove_stops:\n","        txt = \" \".join([w for w in txt.split() if w not in stops])\n","    \n","    if stemming:\n","        st = PorterStemmer()\n","        txt = \" \".join([st.stem(w) for w in txt.split()])\n","\n","    return txt"],"execution_count":0,"outputs":[]},{"metadata":{"id":"x-MaaBLKgk-I","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["## join data\n","test['Is_Response'] = np.nan\n","alldata = pd.concat([train, test]).reset_index(drop=True)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"j5aKySy0gk-L","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# clean description\n","alldata['Description'] = alldata['Description'].map(lambda x: cleanData(x, lowercase=True, remove_stops=False, stemming=False))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"3WY5mMDkgk-O","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# initialise the functions - we'll create separate models for each type.\n","countvec = CountVectorizer(analyzer='word', ngram_range = (1,1), min_df=150, max_features=500)\n","tfidfvec = TfidfVectorizer(analyzer='word', ngram_range = (1,1), min_df = 150, max_features=500)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"sYhl5gbLgk-Q","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# create features\n","bagofwords = countvec.fit_transform(alldata['Description'])\n","tfidfdata = tfidfvec.fit_transform(alldata['Description'])"],"execution_count":0,"outputs":[]},{"metadata":{"id":"4CiDHza5gk-S","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# label encode categorical features in data given\n","cols = ['Browser_Used','Device_Used']\n","\n","for x in cols:\n","    lbl = LabelEncoder()\n","    alldata[x] = lbl.fit_transform(alldata[x])"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Es9xkNjOgk-X","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# create dataframe for features\n","bow_df = pd.DataFrame(bagofwords.todense())\n","tfidf_df = pd.DataFrame(tfidfdata.todense())"],"execution_count":0,"outputs":[]},{"metadata":{"id":"A9MVes5igk-a","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# set column names\n","bow_df.columns = ['col'+ str(x) for x in bow_df.columns]\n","tfidf_df.columns = ['col' + str(x) for x in tfidf_df.columns]"],"execution_count":0,"outputs":[]},{"metadata":{"id":"gAnH2_Iigk-e","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# create separate data frame for bag of words and tf-idf\n","\n","bow_df_train = bow_df[:len(train)]\n","bow_df_test = bow_df[len(train):]\n","\n","tfid_df_train = tfidf_df[:len(train)]\n","tfid_df_test = tfidf_df[len(train):]"],"execution_count":0,"outputs":[]},{"metadata":{"id":"3lw12ZAGgk-i","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# split the merged data file into train and test respectively\n","train_feats = alldata[~pd.isnull(alldata.Is_Response)]\n","test_feats = alldata[pd.isnull(alldata.Is_Response)]"],"execution_count":0,"outputs":[]},{"metadata":{"id":"_JQl-yBJgk-n","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"output_extras":[{}]},"outputId":"acb91f6c-3230-468e-cf49-a56ba9245e2a"},"cell_type":"code","source":["### set target variable\n","\n","train_feats['Is_Response'] = [1 if x == 'happy' else 0 for x in train_feats['Is_Response']]"],"execution_count":0,"outputs":[{"output_type":"stream","text":["c:\\python27\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n","  This is separate from the ipykernel package so we can avoid doing imports until\n"],"name":"stderr"}]},{"metadata":{"id":"f7aM13jwgk-p","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# merge count (bag of word) features into train\n","train_feats1 = pd.concat([train_feats[cols], bow_df_train], axis = 1)\n","test_feats1 = pd.concat([test_feats[cols], bow_df_test], axis=1)\n","\n","test_feats1.reset_index(drop=True, inplace=True)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"shMGOkFJgk-r","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# merge into a new data frame with tf-idf features\n","train_feats2 = pd.concat([train_feats[cols], tfid_df_train], axis=1)\n","test_feats2 = pd.concat([test_feats[cols], tfid_df_test], axis=1)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"lvRu5YX-gk-t","colab_type":"text"},"cell_type":"markdown","source":["### Kmeans ,SVM,Logistic Regression ,KNN etc"]},{"metadata":{"id":"dsFqvO9Ngk-t","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"output_extras":[{}]},"outputId":"287c713e-f54b-4b58-b9cd-c7213470f7f4"},"cell_type":"code","source":["# let's check cross validation score of the model\n","# cv score acts a unbiased estimate of models accuracy on unseen data\n","# from sklearn import linear_model\n","# from sklearn.neighbors import KNeighborsClassifier\n","# from sklearn import svm\n","# from sklearn.cluster import KMeans\n","# from sklearn.linear_model import LogisticRegression\n","from sklearn.svm import SVC\n","from sklearn.ensemble import RandomForestClassifier\n","# from sklearn.cluster import MiniBatchKMeans\n","\n","target = train_feats['Is_Response']\n","# l=  KNeighborsClassifier(n_neighbors=29,weights='distance')\n","# l = KMeans(n_clusters=2).fit(train_feats1,target)\n","# l = RandomForestClassifier( n_estimators=100,criterion='gini')\n","l=LogisticRegression(C=0.5, penalty='l2',solver='sag')\n","l.fit(train_feats2,target)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["LogisticRegression(C=0.5, class_weight=None, dual=False, fit_intercept=True,\n","          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n","          penalty='l2', random_state=None, solver='sag', tol=0.0001,\n","          verbose=0, warm_start=False)"]},"metadata":{"tags":[]},"execution_count":195}]},{"metadata":{"id":"_lOK4dwkgk-z","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["## Naive Bayes 1\n","# print(cross_val_score(mod1, train_feats1, target, cv=5, scoring=make_scorer(accuracy_score)))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"865bFTxbgk-1","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# Naive Bayes 2 - tfidf is giving higher CV score\n","# print(cross_val_score(mod1, train_feats2, target, cv=5, scoring=make_scorer(accuracy_score)))\n","# l.labels_"],"execution_count":0,"outputs":[]},{"metadata":{"id":"qIxhk2r1gk-2","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# make our first set of predictions\n","preds3=l.predict(test_feats2)\n","# clf1 = l\n","# clf1.fit(train_feats1, target)\n","\n","# clf2 = l\n","# clf2.fit(train_feats2, target)\n","# l.cluster_centers_"],"execution_count":0,"outputs":[]},{"metadata":{"id":"42-c3x0pgk-5","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# preds1 = clf1.predict(test_feats1)\n","# preds2 = clf2.predict(test_feats2)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"uhHxT-zEgk-7","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["def to_labels(x):\n","    if x == 1:\n","        return \"happy\"\n","    return \"not_happy\""],"execution_count":0,"outputs":[]},{"metadata":{"id":"g9wThTR-gk-8","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# sub1 = pd.DataFrame({'User_ID':test.User_ID, 'Is_Response':preds1})\n","# sub1['Is_Response'] = sub1['Is_Response'].map(lambda x: to_labels(x))\n","sub3 = pd.DataFrame({'User_ID':test.User_ID,'Is_Response':preds3})\n","sub3['Is_Response'] = sub3['Is_Response'].map(lambda x: to_labels(x))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"zjyWLRh_gk-_","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# sub2 = pd.DataFrame({'User_ID':test.User_ID, 'Is_Response':preds2})\n","# sub2['Is_Response'] = sub2['Is_Response'].map(lambda x: to_labels(x))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"VmN80ylfgk_A","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["\n","\n","# sub1 = sub1[['User_ID', 'Is_Response']]\n","# sub2 = sub2[['User_ID', 'Is_Response']]\n","sub3 = sub3[['User_ID','Is_Response']]"],"execution_count":0,"outputs":[]},{"metadata":{"id":"M-Icno-Vgk_D","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["## write submission files\n","# sub1.to_csv('sub1_cv.csv', index=False)\n","# sub2.to_csv('sub2_tf.csv', index=False)\n","sub3.to_csv('lg_8.csv',index=False)"],"execution_count":0,"outputs":[]}]}